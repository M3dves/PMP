{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "db4a2eae5fce49d2a66036910637bf47": {
     "model_module": "@jupyter-widgets/output",
     "model_name": "OutputModel",
     "model_module_version": "1.0.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_76bf54c65017414ba152615fae3fddd7",
      "msg_id": "",
      "outputs": [
       {
        "output_type": "display_data",
        "data": {
         "text/plain": "                                                                                                                   \n \u001B[1m \u001B[0m\u001B[1mProgress                 \u001B[0m\u001B[1m \u001B[0m \u001B[1m \u001B[0m\u001B[1mDraws\u001B[0m\u001B[1m \u001B[0m \u001B[1m \u001B[0m\u001B[1mDivergences\u001B[0m\u001B[1m \u001B[0m \u001B[1m \u001B[0m\u001B[1mStep size\u001B[0m\u001B[1m \u001B[0m \u001B[1m \u001B[0m\u001B[1mGrad evals\u001B[0m\u001B[1m \u001B[0m \u001B[1m \u001B[0m\u001B[1mSampling Speed\u001B[0m\u001B[1m \u001B[0m \u001B[1m \u001B[0m\u001B[1mElapsed\u001B[0m\u001B[1m \u001B[0m \u001B[1m \u001B[0m\u001B[1mRemaining\u001B[0m\u001B[1m \u001B[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001B[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m   4000    0             0.097       5            183.93 draws/s   0:00:21   0:00:00    \n  \u001B[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m   4000    0             0.107       31           97.06 draws/s    0:00:41   0:00:00    \n                                                                                                                   \n",
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                  </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━━</span>   4000    0             0.097       5            183.93 draws/s   0:00:21   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━━</span>   4000    0             0.107       31           97.06 draws/s    0:00:41   0:00:00    \n                                                                                                                   \n</pre>\n"
        },
        "metadata": {}
       }
      ]
     }
    },
    "76bf54c65017414ba152615fae3fddd7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lzK1sfJYtSUn",
    "outputId": "92f3e007-a640-4a55-bd60-3255212353b0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- IncArcare Si Diagnosticare Date ---\n",
      "Datele au fost incarcate cu succes!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import arviz as az\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# PREGATIREA DATELOR\n",
    "print(\"--- IncArcare Si Diagnosticare Date ---\")\n",
    "try:\n",
    "    df = pd.read_csv('Prices.csv')\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "\n",
    "    col_price = 'price'\n",
    "    col_speed = 'speed'\n",
    "\n",
    "    col_hd = None\n",
    "    possible_hd = ['hd', 'hdd', 'harddrive', 'ads', 'harddisc']\n",
    "    for candidate in possible_hd:\n",
    "        if candidate in df.columns:\n",
    "            col_hd = candidate\n",
    "            break\n",
    "\n",
    "    if not col_hd:\n",
    "        raise KeyError(f\"Nu s-a gasit coloana pentru HDD. Variantele cautate: {possible_hd}\")\n",
    "\n",
    "\n",
    "    y_data = df[col_price].values\n",
    "    x1_data = df[col_speed].values\n",
    "    x2_data = np.log(df[col_hd].values)\n",
    "\n",
    "    if 'premium' in df.columns:\n",
    "        if df['premium'].dtype == 'object':\n",
    "            x3_data = pd.get_dummies(df['premium'], drop_first=True).iloc[:, 0].values\n",
    "        else:\n",
    "            x3_data = df['premium'].values\n",
    "    else:\n",
    "        print(\"Atentie: Coloana 'premium' lipseste. Se folosesc date random.\")\n",
    "        x3_data = np.random.randint(0, 2, size=len(y_data))\n",
    "\n",
    "    print(\"Datele au fost incarcate cu succes!\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"EROARE LA INCARCARE: {e}\")\n",
    "    np.random.seed(42)\n",
    "    N = 500\n",
    "    x1_data = np.random.randint(25, 100, N)\n",
    "    x2_data = np.log(np.random.randint(80, 2000, N))\n",
    "    x3_data = np.random.randint(0, 2, N)\n",
    "    y_data = 1500 + 10 * x1_data + 200 * x2_data + 500 * x3_data + np.random.normal(0, 100, N)\n",
    "    print(\"--> Se folosesc date sintetice.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Punctul a)"
   ],
   "metadata": {
    "id": "aB7l7uOy0sQR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "with pm.Model() as model:\n",
    "    x1_shared = pm.Data('x1_shared', x1_data)\n",
    "    x2_shared = pm.Data('x2_shared', x2_data)\n",
    "\n",
    "    alpha = pm.Normal('alpha', mu=np.mean(y_data), sigma=1000)\n",
    "    beta1 = pm.Normal('beta1', mu=0, sigma=100)\n",
    "    beta2 = pm.Normal('beta2', mu=0, sigma=100)\n",
    "    sigma = pm.HalfCauchy('sigma', beta=100)\n",
    "\n",
    "    mu = pm.Deterministic('mu', alpha + beta1 * x1_shared + beta2 * x2_shared)\n",
    "    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y_data)\n",
    "\n",
    "    idata = pm.sample(2000, tune=2000, return_inferencedata=True, random_seed=42, progressbar=True)\n",
    "\n",
    "print(\"Esantionare completa.\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148,
     "referenced_widgets": [
      "db4a2eae5fce49d2a66036910637bf47",
      "76bf54c65017414ba152615fae3fddd7"
     ]
    },
    "id": "s7TDhpdH0uzH",
    "outputId": "af752a67-30c1-4606-e89c-8c999e052605"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db4a2eae5fce49d2a66036910637bf47"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Esantionare completa.\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Punctul b)"
   ],
   "metadata": {
    "id": "B7uR-FhB012e"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"--- Punctul b) 95% HDI pentru beta1 si beta2 ---\")\n",
    "summary_beta = az.summary(idata, var_names=['beta1', 'beta2'], hdi_prob=0.95)\n",
    "print(summary_beta[['mean', 'sd', 'hdi_2.5%', 'hdi_97.5%']])\n",
    "print(\"\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ohlb1FO03WF",
    "outputId": "547930b4-e129-498a-f69c-ba4f15dc6965"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Punctul b) 95% HDI pentru beta1 si beta2 ---\n",
      "          mean      sd  hdi_2.5%  hdi_97.5%\n",
      "beta1    4.725   1.241     2.362      7.175\n",
      "beta2  291.627  36.329   223.101    364.164\n",
      "\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Punctul c)"
   ],
   "metadata": {
    "id": "F2o0Njkc04N4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "beta1_low = summary_beta.loc['beta1', 'hdi_2.5%']\n",
    "beta1_high = summary_beta.loc['beta1', 'hdi_97.5%']\n",
    "\n",
    "if beta1_low > 0:\n",
    "    print(f\"-> Frecventa procesorului (beta1) ESTE un predictor util (interval pozitiv).\")\n",
    "elif beta1_high < 0:\n",
    "    print(f\"-> Frecventa procesorului (beta1) ESTE un predictor util (interval negativ).\")\n",
    "else:\n",
    "    print(\"-> Frecventa procesorului NU pare a fi un predictor util (intervalul contine 0).\")\n",
    "print(\"\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BunQBVDa06Us",
    "outputId": "eacbff0f-93a5-4561-f1c1-9f64d5e9bd5d"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-> Frecventa procesorului (beta1) ESTE un predictor util (interval pozitiv).\n",
      "\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Punctul d)"
   ],
   "metadata": {
    "id": "lbYk8VC106xy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "new_speed = 33\n",
    "new_hd_log = np.log(540)\n",
    "\n",
    "with model:\n",
    "    pm.set_data({\n",
    "        'x1_shared': [new_speed],\n",
    "        'x2_shared': [new_hd_log]\n",
    "    })\n",
    "\n",
    "    post = idata.posterior\n",
    "\n",
    "    mu_calculated_xr = post['alpha'] + post['beta1'] * new_speed + post['beta2'] * new_hd_log\n",
    "\n",
    "    mu_samples_np = mu_calculated_xr.values.flatten()\n",
    "\n",
    "    mu_hdi = az.hdi(mu_samples_np, hdi_prob=0.90)\n",
    "\n",
    "print(f\"Pentru Speed=33 si HD=540:\")\n",
    "print(f\"Valoarea medie asteptata (mu) 90% HDI: [{mu_hdi[0]:.2f}, {mu_hdi[1]:.2f}]\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "000n3HFD09a2",
    "outputId": "97eef7c7-1c3c-4df2-d5da-e79e507c5eb2"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pentru Speed=33 si HD=540:\n",
      "Valoarea medie asteptata (mu) 90% HDI: [2210.83, 2340.12]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Punctul e)"
   ],
   "metadata": {
    "id": "ljVpKKDw097l"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "with model:\n",
    "    try:\n",
    "        post_pred = pm.sample_posterior_predictive(idata, predictions=True, random_seed=42, progressbar=False)\n",
    "    except TypeError:\n",
    "        post_pred = pm.sample_posterior_predictive(idata, random_seed=42, progressbar=False)\n",
    "\n",
    "if isinstance(post_pred, az.InferenceData):\n",
    "    if hasattr(post_pred, 'predictions') and 'y_obs' in post_pred.predictions:\n",
    "        y_samples_xr = post_pred.predictions['y_obs']\n",
    "    elif hasattr(post_pred, 'posterior_predictive') and 'y_obs' in post_pred.posterior_predictive:\n",
    "        y_samples_xr = post_pred.posterior_predictive['y_obs']\n",
    "    else:\n",
    "        raise ValueError(\"Nu s-au gasit predictiile in obiectul InferenceData.\")\n",
    "else:\n",
    "    y_samples_xr = post_pred['y_obs']\n",
    "\n",
    "if hasattr(y_samples_xr, 'values'):\n",
    "    y_samples_np = y_samples_xr.values.flatten()\n",
    "else:\n",
    "    y_samples_np = np.array(y_samples_xr).flatten()\n",
    "\n",
    "y_hdi = az.hdi(y_samples_np, hdi_prob=0.90)\n",
    "\n",
    "print(f\"Pretul prezis (y_pred) 90% HDI: [{y_hdi[0]:.2f}, {y_hdi[1]:.2f}]\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8NjDMer0_lx",
    "outputId": "6109e268-b8eb-4615-cfd3-de007183e513"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pretul prezis (y_pred) 90% HDI: [1447.40, 3107.72]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bonus:\n",
    "Faptul ca producatorul este Premium afectează pretul"
   ],
   "metadata": {
    "id": "EUNCiT6v0_5x"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "with pm.Model() as model_bonus:\n",
    "    alpha = pm.Normal('alpha', mu=np.mean(y_data), sigma=1000)\n",
    "    beta1 = pm.Normal('beta1', mu=0, sigma=100)\n",
    "    beta2 = pm.Normal('beta2', mu=0, sigma=100)\n",
    "    beta3 = pm.Normal('beta3', mu=0, sigma=100)\n",
    "    sigma = pm.HalfCauchy('sigma', beta=100)\n",
    "\n",
    "    mu = alpha + beta1 * x1_data + beta2 * x2_data + beta3 * x3_data\n",
    "    y = pm.Normal('y', mu=mu, sigma=sigma, observed=y_data)\n",
    "\n",
    "    idata_bonus = pm.sample(1000, tune=1000, return_inferencedata=True, progressbar=False, random_seed=42)\n",
    "\n",
    "summary_bonus = az.summary(idata_bonus, var_names=['beta3'], hdi_prob=0.95)\n",
    "print(summary_bonus[['mean', 'hdi_2.5%', 'hdi_97.5%']])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ZWuudeU1A92",
    "outputId": "08f5285c-478b-4563-ab04-19851c7028d8"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          mean  hdi_2.5%  hdi_97.5%\n",
      "beta3 -194.379   -307.42    -81.905\n"
     ]
    }
   ]
  }
 ]
}
